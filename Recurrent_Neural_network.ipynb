{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Activation, Dense, LSTM"
      ],
      "metadata": {
        "id": "psMXYlU6GM-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
        "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmram2YvWxfQ",
        "outputId": "753e5536-35d4-4877-a6f7-866804fd0a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text[300000:800000]"
      ],
      "metadata": {
        "id": "kHLVbmzuW5Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characters = sorted(set(text))\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))"
      ],
      "metadata": {
        "id": "6Ac_XbxuW6Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "sentences = []\n",
        "next_char = []"
      ],
      "metadata": {
        "id": "Ryz-5CKqW8ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i + SEQ_LENGTH])\n",
        "    next_char.append(text[i + SEQ_LENGTH])"
      ],
      "metadata": {
        "id": "JOc_Gr_JW9td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
        "              len(characters)), dtype=np.bool_)\n",
        "y = np.zeros((len(sentences),\n",
        "              len(characters)), dtype=np.bool_)\n",
        "\n",
        "for i, satz in enumerate(sentences):\n",
        "    for t, char in enumerate(satz):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_char[i]]] = 1"
      ],
      "metadata": {
        "id": "1LZMdsmFW_g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128,\n",
        "               input_shape=(SEQ_LENGTH,\n",
        "                            len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "SI4rJ3cYXIMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.01))\n",
        "\n",
        "model.fit(x, y, batch_size=256, epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZRQNH-pXO3d",
        "outputId": "123ff3d6-f256-4642-cc0b-0c174009b07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "651/651 [==============================] - 122s 185ms/step - loss: 2.7008\n",
            "Epoch 2/4\n",
            "651/651 [==============================] - 115s 177ms/step - loss: 2.3058\n",
            "Epoch 3/4\n",
            "651/651 [==============================] - 118s 182ms/step - loss: 2.1929\n",
            "Epoch 4/4\n",
            "651/651 [==============================] - 117s 180ms/step - loss: 2.1169\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e2c381ceb30>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "49kziomlXP97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_predictions[0, t, char_to_index[char]] = 1\n",
        "\n",
        "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
        "        next_index = sample(predictions,\n",
        "                                 temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated"
      ],
      "metadata": {
        "id": "vucS4HWhXSU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.2))\n",
        "print(generate_text(300, 0.4))\n",
        "print(generate_text(300, 0.5))\n",
        "print(generate_text(300, 0.6))\n",
        "print(generate_text(300, 0.7))\n",
        "print(generate_text(300, 0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NALEEQAXXO7",
        "outputId": "654d7fa8-e4f0-4378-9aed-849bd2075eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mned and myself excused.\n",
            "\n",
            "prince:\n",
            "then shear that the that the the the that the come the fares and and the the the ware the carete the thee sount the thee the the that the that the the the the the the the the count the fares that the that the for the the that the the the the the the the the and the with the the the the the the the the tha\n",
            "rwick:\n",
            "deposed he shall be, in despite on the mare coreat the thes and the mansen the thath mare the parise his and the hare the nome the the fore hith the thear in mant the carenterus, the the wather, the bead i beant the coust that seate the i hate i court the prast, and have the ast lath nower hath the faren.\n",
            "\n",
            "king and is there,\n",
            "me the\n",
            "y finds\n",
            "the trembling lamb environed with the wase fardule sone the that whe lave camerout the comest the a fath seard stous ins benterd!\n",
            "\n",
            "ardice:\n",
            "and the the sanes end of the and bule:\n",
            "the math and mean's with the candes:\n",
            "and the thate the the and hand and the comen the mence the sain that that the the mand soref are foren to shace the c\n",
            "sweet and delectable.\n",
            "but i bethink me wart the farenrey:\n",
            "\n",
            "hour are ay the the seecreas.\n",
            "\n",
            "lathard:\n",
            "acus the seasper the. fave lathing duent?\n",
            "\n",
            "sured:\n",
            "and, and the pathes.\n",
            "\n",
            "betold:\n",
            "the ravenged the ceastores bearas.\n",
            "\n",
            "murea:\n",
            "for if the are, you rowest then to list werew you on ther and if the siant.\n",
            "\n",
            "canat crat:\n",
            "co fare 'llavy catwerd this b\n",
            " london they do bend their course,\n",
            "if by pray and hends hif our ow decl is the kime lalles my bears thoued my thame the bate you desing and stith the camase sheef; as the mate the monre eras rich, wath the tiesteres my bute thi kearse thas is ryout stee.\n",
            "\n",
            "jromen:\n",
            "comeast thou therear and the bomen the kece the coupar to, from,\n",
            "thar mand t\n",
            "not so, then here i hit it right,\n",
            "our rofcaos, and mest the this ithes the cwalie!\n",
            "\n",
            "whithes deake, end the be tous say shat, the thee wort my hithes the myours lith mespar.\n",
            "\n",
            "ay i, theus thy buseife farsule, the the bosp of ae the' spanture wall the bleabe, no hast rompore.\n",
            "ard marine parnorenor shant tus gon thy harthes,\n",
            "\n",
            "theat tro keds w\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-7ODVoCaXYJg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}